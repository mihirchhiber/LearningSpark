{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\m\\documents\\github\\learningspark\\.venv\\lib\\site-packages (3.5.5)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\m\\documents\\github\\learningspark\\.venv\\lib\\site-packages (from pyspark) (0.10.9.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the code below if pyspark operations throw random errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(\"C:/Users/m/AppData/Local/Temp\", ignore_errors=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing library and loading CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('Practise').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InferSchema checks the data values for the column and allocates an appropriate data type accordingly\n",
    "\n",
    "df = spark.read.option('header','true').option('delimiter',';').csv(\"username.csv\", inferSchema=True)\n",
    "# or\n",
    "df = spark.read.csv(\"username.csv\", header=True, sep=\";\", inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+----------+---------+\n",
      "| Username| Identifier|First name|Last name|\n",
      "+---------+-----------+----------+---------+\n",
      "| booker12|       9012|    Rachel|   Booker|\n",
      "|   grey07|       2070|     Laura|     Grey|\n",
      "|johnson81|       4081|     Craig|  Johnson|\n",
      "|jenkins46|       9346|      Mary|  Jenkins|\n",
      "|  smith79|       5079|     Jamie|    Smith|\n",
      "+---------+-----------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To see the table\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Username: string (nullable = true)\n",
      " |--  Identifier: integer (nullable = true)\n",
      " |-- First name: string (nullable = true)\n",
      " |-- Last name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To see the schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Username='booker12',  Identifier=9012, First name='Rachel', Last name='Booker')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see a row of values from the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "| Username|\n",
      "+---------+\n",
      "| booker12|\n",
      "|   grey07|\n",
      "|johnson81|\n",
      "|jenkins46|\n",
      "|  smith79|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Selecting a column and displaying all of its values\n",
    "df.select(\"Username\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "| Username| Identifier|\n",
      "+---------+-----------+\n",
      "| booker12|       9012|\n",
      "|   grey07|       2070|\n",
      "|johnson81|       4081|\n",
      "|jenkins46|       9346|\n",
      "|  smith79|       5079|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Selecting more than one column and displaying all of its values\n",
    "df.select([\"Username\",\" Identifier\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------------------+----------+---------+\n",
      "|summary|Username|        Identifier|First name|Last name|\n",
      "+-------+--------+------------------+----------+---------+\n",
      "|  count|       5|                 5|         5|        5|\n",
      "|   mean|    NULL|            5917.6|      NULL|     NULL|\n",
      "| stddev|    NULL|3170.5525228262663|      NULL|     NULL|\n",
      "|    min|booker12|              2070|     Craig|   Booker|\n",
      "|    max| smith79|              9346|    Rachel|    Smith|\n",
      "+-------+--------+------------------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gives summary of all the columns such as count, mean, average, standard deviation, minimum, maximum\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+----------+---------+------------------+\n",
      "| Username| Identifier|First name|Last name|Updated Identifier|\n",
      "+---------+-----------+----------+---------+------------------+\n",
      "| booker12|       9012|    Rachel|   Booker|              9017|\n",
      "|   grey07|       2070|     Laura|     Grey|              2075|\n",
      "|johnson81|       4081|     Craig|  Johnson|              4086|\n",
      "|jenkins46|       9346|      Mary|  Jenkins|              9351|\n",
      "|  smith79|       5079|     Jamie|    Smith|              5084|\n",
      "+---------+-----------+----------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To create a new column, in the example given below, we use one of the columns already in the dataframe\n",
    "df = df.withColumn('Updated Identifier', df[' Identifier'] + 5)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+----------+---------+\n",
      "| Username| Identifier|First name|Last name|\n",
      "+---------+-----------+----------+---------+\n",
      "| booker12|       9012|    Rachel|   Booker|\n",
      "|   grey07|       2070|     Laura|     Grey|\n",
      "|johnson81|       4081|     Craig|  Johnson|\n",
      "|jenkins46|       9346|      Mary|  Jenkins|\n",
      "|  smith79|       5079|     Jamie|    Smith|\n",
      "+---------+-----------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dropping a column\n",
    "df = df.drop(\"Updated Identifier\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+----------+---------+\n",
      "| New Name| Identifier|First name|Last name|\n",
      "+---------+-----------+----------+---------+\n",
      "| booker12|       9012|    Rachel|   Booker|\n",
      "|   grey07|       2070|     Laura|     Grey|\n",
      "|johnson81|       4081|     Craig|  Johnson|\n",
      "|jenkins46|       9346|      Mary|  Jenkins|\n",
      "|  smith79|       5079|     Jamie|    Smith|\n",
      "+---------+-----------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Renaming columns\n",
    "df.withColumnRenamed(\"Username\",\"New Name\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values\n",
    "- Dropping columns\n",
    "- Dropping rows\n",
    "- Various parameter in dropping functionalities\n",
    "- Handling missing values in mean, median and mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values\n",
    "- Dropping columns\n",
    "- Dropping rows\n",
    "- Various parameter in dropping functionalities\n",
    "- Handling missing values in mean, median and mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading another csv\n",
    "df = spark.read.csv('biostats.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+---+-----------+------------+\n",
      "|Name|Sex|Age|Height (in)|Weight (lbs)|\n",
      "+----+---+---+-----------+------------+\n",
      "|Alex|  M| 41|         74|         170|\n",
      "|Bert|  M| 42|         68|         166|\n",
      "|Carl|  M| 32|         70|         155|\n",
      "|Dave|  M| 39|         72|         167|\n",
      "|Elly|  F| 30|         66|         124|\n",
      "|Fran|  F| 33|         66|         115|\n",
      "|Gwen|  F| 26|         64|         121|\n",
      "|Hank|  M| 30|         71|         158|\n",
      "|Ivan|  M| 53|         72|         175|\n",
      "|Kate|  F| 47|         69|         139|\n",
      "|Luke|  M| 34|         72|         163|\n",
      "|Myra|  F| 23|         62|          98|\n",
      "|Neil|  M| 36|         75|         160|\n",
      "|Page|  F| 31|         67|         135|\n",
      "|Ruth|  F| 28|         65|         131|\n",
      "+----+---+---+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# By default drops any row with null value\n",
    "df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---+-----------+------------+\n",
      "|Name| Sex|Age|Height (in)|Weight (lbs)|\n",
      "+----+----+---+-----------+------------+\n",
      "|Alex|   M| 41|         74|         170|\n",
      "|Bert|   M| 42|         68|         166|\n",
      "|Carl|   M| 32|         70|         155|\n",
      "|Dave|   M| 39|         72|         167|\n",
      "|Elly|   F| 30|         66|         124|\n",
      "|Fran|   F| 33|         66|         115|\n",
      "|Gwen|   F| 26|         64|         121|\n",
      "|Hank|   M| 30|         71|         158|\n",
      "|Ivan|   M| 53|         72|         175|\n",
      "|Jake|NULL| 32|         69|         143|\n",
      "|Kate|   F| 47|         69|         139|\n",
      "|Luke|   M| 34|         72|         163|\n",
      "|Myra|   F| 23|         62|          98|\n",
      "|Neil|   M| 36|         75|         160|\n",
      "|Omar|   M| 38|       NULL|        NULL|\n",
      "|Page|   F| 31|         67|         135|\n",
      "|Ruth|   F| 28|         65|         131|\n",
      "+----+----+---+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assigning value how=\"all\" will drop only the columns with all values as null \n",
    "df.na.drop(how=\"all\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---+-----------+------------+\n",
      "|Name| Sex|Age|Height (in)|Weight (lbs)|\n",
      "+----+----+---+-----------+------------+\n",
      "|Alex|   M| 41|         74|         170|\n",
      "|Bert|   M| 42|         68|         166|\n",
      "|Carl|   M| 32|         70|         155|\n",
      "|Dave|   M| 39|         72|         167|\n",
      "|Elly|   F| 30|         66|         124|\n",
      "|Fran|   F| 33|         66|         115|\n",
      "|Gwen|   F| 26|         64|         121|\n",
      "|Hank|   M| 30|         71|         158|\n",
      "|Ivan|   M| 53|         72|         175|\n",
      "|Jake|NULL| 32|         69|         143|\n",
      "|Kate|   F| 47|         69|         139|\n",
      "|Luke|   M| 34|         72|         163|\n",
      "|Myra|   F| 23|         62|          98|\n",
      "|Neil|   M| 36|         75|         160|\n",
      "|Omar|   M| 38|       NULL|        NULL|\n",
      "|Page|   F| 31|         67|         135|\n",
      "|Ruth|   F| 28|         65|         131|\n",
      "+----+----+---+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assigning value how=\"any\" and threshold to 2 so it will discard if there are 2 null values in a row \n",
    "df.na.drop(how=\"all\", thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----+-----------+------------+\n",
      "|   Name|    Sex| Age|Height (in)|Weight (lbs)|\n",
      "+-------+-------+----+-----------+------------+\n",
      "|   Alex|      M|  41|         74|         170|\n",
      "|   Bert|      M|  42|         68|         166|\n",
      "|   Carl|      M|  32|         70|         155|\n",
      "|   Dave|      M|  39|         72|         167|\n",
      "|   Elly|      F|  30|         66|         124|\n",
      "|   Fran|      F|  33|         66|         115|\n",
      "|   Gwen|      F|  26|         64|         121|\n",
      "|   Hank|      M|  30|         71|         158|\n",
      "|   Ivan|      M|  53|         72|         175|\n",
      "|   Jake|Nothing|  32|         69|         143|\n",
      "|   Kate|      F|  47|         69|         139|\n",
      "|   Luke|      M|  34|         72|         163|\n",
      "|   Myra|      F|  23|         62|          98|\n",
      "|   Neil|      M|  36|         75|         160|\n",
      "|   Omar|      M|  38|       NULL|        NULL|\n",
      "|   Page|      F|  31|         67|         135|\n",
      "|Nothing|Nothing|NULL|       NULL|        NULL|\n",
      "|   Ruth|      F|  28|         65|         131|\n",
      "+-------+-------+----+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replacing all the null values with a value\n",
    "df.na.fill(\"Nothing\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting columns to a specific data type\n",
    "\n",
    "from pyspark.sql.types import FloatType\n",
    "df = df.withColumn(\"Height (in)\", df[\"Height (in)\"].cast(FloatType()))\n",
    "df = df.withColumn(\"Weight (lbs)\", df[\"Weight (lbs)\"].cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To replace null values with mean/median/mode instead of a fixed value, use imputer for the specific columns\n",
    "\n",
    "from pyspark.ml.feature import Imputer\n",
    "imputer = Imputer(\n",
    "    inputCols=[\"Age\", \"Height (in)\", \"Weight (lbs)\"],\n",
    "    outputCols=[\"{}_imputed\".format(c) for c in [\"Age\", \"Height (in)\", \"Weight (lbs)\"]]\n",
    ").setStrategy(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+-----------+------------+-----------+-------------------+--------------------+\n",
      "|Name| Sex| Age|Height (in)|Weight (lbs)|Age_imputed|Height (in)_imputed|Weight (lbs)_imputed|\n",
      "+----+----+----+-----------+------------+-----------+-------------------+--------------------+\n",
      "|Alex|   M|  41|       74.0|       170.0|         41|               74.0|               170.0|\n",
      "|Bert|   M|  42|       68.0|       166.0|         42|               68.0|               166.0|\n",
      "|Carl|   M|  32|       70.0|       155.0|         32|               70.0|               155.0|\n",
      "|Dave|   M|  39|       72.0|       167.0|         39|               72.0|               167.0|\n",
      "|Elly|   F|  30|       66.0|       124.0|         30|               66.0|               124.0|\n",
      "|Fran|   F|  33|       66.0|       115.0|         33|               66.0|               115.0|\n",
      "|Gwen|   F|  26|       64.0|       121.0|         26|               64.0|               121.0|\n",
      "|Hank|   M|  30|       71.0|       158.0|         30|               71.0|               158.0|\n",
      "|Ivan|   M|  53|       72.0|       175.0|         53|               72.0|               175.0|\n",
      "|Jake|NULL|  32|       69.0|       143.0|         32|               69.0|               143.0|\n",
      "|Kate|   F|  47|       69.0|       139.0|         47|               69.0|               139.0|\n",
      "|Luke|   M|  34|       72.0|       163.0|         34|               72.0|               163.0|\n",
      "|Myra|   F|  23|       62.0|        98.0|         23|               62.0|                98.0|\n",
      "|Neil|   M|  36|       75.0|       160.0|         36|               75.0|               160.0|\n",
      "|Omar|   M|  38|       NULL|        NULL|         38|             68.875|               145.0|\n",
      "|Page|   F|  31|       67.0|       135.0|         31|               67.0|               135.0|\n",
      "|NULL|NULL|NULL|       NULL|        NULL|         35|             68.875|               145.0|\n",
      "|Ruth|   F|  28|       65.0|       131.0|         28|               65.0|               131.0|\n",
      "+----+----+----+-----------+------------+-----------+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fitting the data here to calculate the mean and then using the same data here to fill the null values\n",
    "imputer.fit(df).transform(df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Operstions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---+-----------+------------+\n",
      "|Name| Sex|Age|Height (in)|Weight (lbs)|\n",
      "+----+----+---+-----------+------------+\n",
      "|Carl|   M| 32|       70.0|       155.0|\n",
      "|Dave|   M| 39|       72.0|       167.0|\n",
      "|Elly|   F| 30|       66.0|       124.0|\n",
      "|Fran|   F| 33|       66.0|       115.0|\n",
      "|Gwen|   F| 26|       64.0|       121.0|\n",
      "|Hank|   M| 30|       71.0|       158.0|\n",
      "|Jake|NULL| 32|       69.0|       143.0|\n",
      "|Luke|   M| 34|       72.0|       163.0|\n",
      "|Myra|   F| 23|       62.0|        98.0|\n",
      "|Neil|   M| 36|       75.0|       160.0|\n",
      "|Omar|   M| 38|       NULL|        NULL|\n",
      "|Page|   F| 31|       67.0|       135.0|\n",
      "|Ruth|   F| 28|       65.0|       131.0|\n",
      "+----+----+---+-----------+------------+\n",
      "\n",
      "+----+---+\n",
      "|Name|Age|\n",
      "+----+---+\n",
      "|Alex| 41|\n",
      "|Bert| 42|\n",
      "|Carl| 32|\n",
      "|Dave| 39|\n",
      "|Hank| 30|\n",
      "|Ivan| 53|\n",
      "|Luke| 34|\n",
      "|Neil| 36|\n",
      "|Omar| 38|\n",
      "+----+---+\n",
      "\n",
      "+----+---+\n",
      "|Name|Age|\n",
      "+----+---+\n",
      "|Carl| 32|\n",
      "|Dave| 39|\n",
      "|Hank| 30|\n",
      "|Luke| 34|\n",
      "|Neil| 36|\n",
      "|Omar| 38|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtering out data similar to SQL commands\n",
    "df.filter(\"Age<=40\").show()\n",
    "\n",
    "df.filter(\"Sex='M'\").select([\"Name\",\"Age\"]).show()\n",
    "\n",
    "df.filter(\"Sex='M' and Age<=40\").select([\"Name\",\"Age\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+---+-----------+------------+\n",
      "|Name|Sex|Age|Height (in)|Weight (lbs)|\n",
      "+----+---+---+-----------+------------+\n",
      "|Elly|  F| 30|       66.0|       124.0|\n",
      "|Fran|  F| 33|       66.0|       115.0|\n",
      "|Gwen|  F| 26|       64.0|       121.0|\n",
      "|Kate|  F| 47|       69.0|       139.0|\n",
      "|Myra|  F| 23|       62.0|        98.0|\n",
      "|Page|  F| 31|       67.0|       135.0|\n",
      "|Ruth|  F| 28|       65.0|       131.0|\n",
      "+----+---+---+-----------+------------+\n",
      "\n",
      "+----+---+---+-----------+------------+\n",
      "|Name|Sex|Age|Height (in)|Weight (lbs)|\n",
      "+----+---+---+-----------+------------+\n",
      "|Alex|  M| 41|       74.0|       170.0|\n",
      "|Bert|  M| 42|       68.0|       166.0|\n",
      "|Carl|  M| 32|       70.0|       155.0|\n",
      "|Dave|  M| 39|       72.0|       167.0|\n",
      "|Hank|  M| 30|       71.0|       158.0|\n",
      "|Ivan|  M| 53|       72.0|       175.0|\n",
      "|Luke|  M| 34|       72.0|       163.0|\n",
      "|Neil|  M| 36|       75.0|       160.0|\n",
      "|Omar|  M| 38|       NULL|        NULL|\n",
      "+----+---+---+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtering out data similar to pandas style\n",
    "\n",
    "df.filter(df[\"Sex\"]==\"F\").show()\n",
    "\n",
    "df.filter(~(df[\"Sex\"]==\"F\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group By and Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the data to use it in the group by and aggregate operations\n",
    "df = df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-----------------+------------------+\n",
      "|Sex|          avg(Age)| avg(Height (in))| avg(Weight (lbs))|\n",
      "+---+------------------+-----------------+------------------+\n",
      "|  F|31.142857142857142|65.57142857142857|123.28571428571429|\n",
      "|  M|            38.375|            71.75|            164.25|\n",
      "+---+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To group data based on \"Sex\" and then calculate mean for the rest\n",
    "df.groupBy(\"Sex\").mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|max(Age)|\n",
      "+--------+\n",
      "|      53|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To get the maximum value of column \"Age\"\n",
    "df.agg({'Age':'max'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+---+-----------+------------+------------+\n",
      "|Name|Sex|Age|Height (in)|Weight (lbs)|      vector|\n",
      "+----+---+---+-----------+------------+------------+\n",
      "|Alex|  M| 41|       74.0|       170.0|[170.0,74.0]|\n",
      "|Bert|  M| 42|       68.0|       166.0|[166.0,68.0]|\n",
      "|Carl|  M| 32|       70.0|       155.0|[155.0,70.0]|\n",
      "|Dave|  M| 39|       72.0|       167.0|[167.0,72.0]|\n",
      "|Elly|  F| 30|       66.0|       124.0|[124.0,66.0]|\n",
      "|Fran|  F| 33|       66.0|       115.0|[115.0,66.0]|\n",
      "|Gwen|  F| 26|       64.0|       121.0|[121.0,64.0]|\n",
      "|Hank|  M| 30|       71.0|       158.0|[158.0,71.0]|\n",
      "|Ivan|  M| 53|       72.0|       175.0|[175.0,72.0]|\n",
      "|Kate|  F| 47|       69.0|       139.0|[139.0,69.0]|\n",
      "|Luke|  M| 34|       72.0|       163.0|[163.0,72.0]|\n",
      "|Myra|  F| 23|       62.0|        98.0| [98.0,62.0]|\n",
      "|Neil|  M| 36|       75.0|       160.0|[160.0,75.0]|\n",
      "|Page|  F| 31|       67.0|       135.0|[135.0,67.0]|\n",
      "|Ruth|  F| 28|       65.0|       131.0|[131.0,65.0]|\n",
      "+----+---+---+-----------+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To assemble a vector with list of columns to give as training input\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "featureassembler = VectorAssembler(inputCols=[\"Weight (lbs)\", \"Height (in)\"], outputCol=\"vector\")\n",
    "output=featureassembler.transform(df)\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+\n",
      "|      Vector|Age|\n",
      "+------------+---+\n",
      "|[170.0,74.0]| 41|\n",
      "|[166.0,68.0]| 42|\n",
      "|[155.0,70.0]| 32|\n",
      "|[167.0,72.0]| 39|\n",
      "|[124.0,66.0]| 30|\n",
      "|[115.0,66.0]| 33|\n",
      "|[121.0,64.0]| 26|\n",
      "|[158.0,71.0]| 30|\n",
      "|[175.0,72.0]| 53|\n",
      "|[139.0,69.0]| 47|\n",
      "|[163.0,72.0]| 34|\n",
      "| [98.0,62.0]| 23|\n",
      "|[160.0,75.0]| 36|\n",
      "|[135.0,67.0]| 31|\n",
      "|[131.0,65.0]| 28|\n",
      "+------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting the final data to for the regression model\n",
    "data = output.select([\"Vector\", \"Age\"])\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test\n",
    "train_df, test_df = data.randomSplit([0.75,0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the regression model using the test data\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "regressor = LinearRegression(featuresCol=\"Vector\", labelCol=\"Age\")\n",
    "regressor = regressor.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+------------------+\n",
      "|      Vector|Age|        prediction|\n",
      "+------------+---+------------------+\n",
      "| [98.0,62.0]| 23|24.281106476696316|\n",
      "|[155.0,70.0]| 32|  37.8372949122352|\n",
      "+------------+---+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating based on the test data\n",
    "results = regressor.evaluate(test_df)\n",
    "results.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.857622848520105"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the Mean Squared Error for the test data/evaluation\n",
    "results.meanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.281106476696316"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting using the regression model\n",
    "regressor.predict(test_df.select(\"Vector\").first()[\"Vector\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
